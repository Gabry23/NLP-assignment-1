{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabry23/NLP-assignment-1/blob/main/NLP2024_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
        "\n",
        "**Keywords**: POS tagging, Sequence labelling, RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9ipqol6UOBE"
      },
      "source": [
        "\n",
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "* Eleonora Mancini -> e.mancini@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHwQmVBJUOBE"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "You are tasked to address the task of POS tagging.\n",
        "\n",
        "<center>\n",
        "    <img src=\"images/pos_tagging.png\" alt=\"POS tagging\" />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VtItuaJUOBE"
      },
      "source": [
        "# [Task 1 - 0.5 points] Corpus\n",
        "\n",
        "You are going to work with the [Penn TreeBank corpus](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip).\n",
        "\n",
        "**Ignore** the numeric value in the third column, use **only** the words/symbols and their POS label.\n",
        "\n",
        "### Example\n",
        "\n",
        "```Pierre\tNNP\t2\n",
        "Vinken\tNNP\t8\n",
        ",\t,\t2\n",
        "61\tCD\t5\n",
        "years\tNNS\t6\n",
        "old\tJJ\t2\n",
        ",\t,\t2\n",
        "will\tMD\t0\n",
        "join\tVB\t8\n",
        "the\tDT\t11\n",
        "board\tNN\t9\n",
        "as\tIN\t9\n",
        "a\tDT\t15\n",
        "nonexecutive\tJJ\t15\n",
        "director\tNN\t12\n",
        "Nov.\tNNP\t9\n",
        "29\tCD\t16\n",
        ".\t.\t8\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWFfLjTQUOBF"
      },
      "source": [
        "### Splits\n",
        "\n",
        "The corpus contains 200 documents.\n",
        "\n",
        "   * **Train**: Documents 1-100\n",
        "   * **Validation**: Documents 101-150\n",
        "   * **Test**: Documents 151-199"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g6CmDE5UOBF"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Download** the corpus.\n",
        "* **Encode** the corpus into a pandas.DataFrame object.\n",
        "* **Split** it in training, validation, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, GRU, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import normalize\n"
      ],
      "metadata": {
        "id": "o328KfoMW7Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"dependency_treebank\"\n",
        "url = 'https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip'\n",
        "dataset_path = os.path.join(\"Datasets\", \"dependency_treebank.zip\")\n",
        "dataset_folder = os.path.join(os.getcwd(), \"Datasets\")\n",
        "\n",
        "if not os.path.exists(dataset_folder):\n",
        "    os.makedirs(dataset_folder)\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    urllib.request.urlretrieve(url, dataset_path)\n",
        "    print(\"Download done for dataset!\")\n",
        "\n",
        "with zipfile.ZipFile(dataset_path,\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"Datasets\")\n",
        "    print(\"Extraction done for dataset!\")\n",
        "\n",
        "\n",
        "\n",
        "url_glove = 'https://nlp.stanford.edu/data/glove.6B.zip'\n",
        "glove_path = os.path.join(\"Datasets\", \"glove.6B.zip\")\n",
        "dataset_folder_glove = os.path.join(os.getcwd(), \"Datasets/glove\")\n",
        "\n",
        "if not os.path.exists(dataset_folder_glove):\n",
        "    os.makedirs(dataset_folder_glove)\n",
        "\n",
        "if not os.path.exists(glove_path):\n",
        "    urllib.request.urlretrieve(url_glove, glove_path)\n",
        "    print(\"Download done for glove!\")\n",
        "\n",
        "with zipfile.ZipFile(glove_path,\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"glove\")\n",
        "    print(\"Extraction done for glove!\")"
      ],
      "metadata": {
        "id": "9j-FajCOW9oP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679dda61-b5a0-414d-9a84-cb6e15cafc2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download done for dataset!\n",
            "Extraction done for dataset!\n",
            "Download done for glove!\n",
            "Extraction done for glove!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "EMBEDDING_DIMENSION = 50\n",
        "\n",
        "glove_file = os.path.join(os.getcwd(), \"glove\", f\"glove.6B.{str(EMBEDDING_DIMENSION)}d.txt\")\n",
        "with open(glove_file, encoding = \"utf8\" ) as text_file:\n",
        "  lines = text_file.readlines()\n",
        "\n",
        "\n",
        "embedding_vocabulary = {}\n",
        "\n",
        "for line in lines:\n",
        "  splits = line.split()\n",
        "  embedding_vocabulary[splits[0]] = np.array([float(val) for val in splits[1:]])"
      ],
      "metadata": {
        "id": "BZD6Gwi22OVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(sentence, vocabulary, embedding_size):\n",
        "\n",
        "  embeddings = []\n",
        "  for word in sentence:\n",
        "    embedding = vocabulary.get(word.lower())\n",
        "    if embedding is not None:\n",
        "      embeddings.append(embedding)\n",
        "    else:\n",
        "      embeddings.append(list(np.zeros(embedding_size)))\n",
        "\n",
        "  return embeddings"
      ],
      "metadata": {
        "id": "L7wy2y3bwXn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_rows = []\n",
        "row_words = []\n",
        "row_tags = []\n",
        "folder = os.path.join(\"Datasets\", \"dependency_treebank\")\n",
        "\n",
        "\n",
        "for filename in sorted(os.listdir(folder)):\n",
        "  file_path = os.path.join(folder, filename)\n",
        "  if os.path.isfile(file_path):\n",
        "\n",
        "\n",
        "    with open(file_path, mode = \"r\") as text_file:\n",
        "      while True:\n",
        "        line = text_file.readline()\n",
        "\n",
        "\n",
        "        if line and line != \"\\n\":\n",
        "          row_words.append(line.split()[0])\n",
        "          row_tags.append(line.split()[1])\n",
        "\n",
        "        else:\n",
        "          dataframe_row = {\"file_id\": int(filename.split(\".\")[0].split(\"_\")[1]),\n",
        "                           \"sentence\": row_words,\n",
        "                           \"tags\": row_tags,\n",
        "                           \"features\": get_embeddings(row_words, embedding_vocabulary, EMBEDDING_DIMENSION)}\n",
        "          dataframe_rows.append(dataframe_row)\n",
        "          row_words = []\n",
        "          row_tags = []\n",
        "\n",
        "          if not line: break\n",
        "\n",
        "dataframe = pd.DataFrame(dataframe_rows)\n",
        "dataframe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Xhqf3FBlVcR8",
        "outputId": "52a32d2a-e2b0-4928-817c-a6d629b9d184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   file_id                                           sentence  \\\n",
              "0        1  [Pierre, Vinken, ,, 61, years, old, ,, will, j...   \n",
              "1        1  [Mr., Vinken, is, chairman, of, Elsevier, N.V....   \n",
              "2        2  [Rudolph, Agnew, ,, 55, years, old, and, forme...   \n",
              "3        3  [A, form, of, asbestos, once, used, to, make, ...   \n",
              "4        3  [The, asbestos, fiber, ,, crocidolite, ,, is, ...   \n",
              "\n",
              "                                                tags  \\\n",
              "0  [NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...   \n",
              "1  [NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...   \n",
              "2  [NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...   \n",
              "3  [DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...   \n",
              "4  [DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...   \n",
              "\n",
              "                                            features  \n",
              "0  [[0.23568, 0.39638, -0.60135, -0.52681, 0.1587...  \n",
              "1  [[0.006008, 0.57028, -0.064426, -0.044687, 0.8...  \n",
              "2  [[0.86274, 0.056588, -0.081828, -0.35318, -0.0...  \n",
              "3  [[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...  \n",
              "4  [[0.418, 0.24968, -0.41242, 0.1217, 0.34527, -...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-161caebd-5ea9-4e56-8a8a-a05d1cca5fa0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>tags</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[Pierre, Vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "      <td>[[0.23568, 0.39638, -0.60135, -0.52681, 0.1587...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[Mr., Vinken, is, chairman, of, Elsevier, N.V....</td>\n",
              "      <td>[NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
              "      <td>[[0.006008, 0.57028, -0.064426, -0.044687, 0.8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[Rudolph, Agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "      <td>[[0.86274, 0.056588, -0.081828, -0.35318, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[A, form, of, asbestos, once, used, to, make, ...</td>\n",
              "      <td>[DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...</td>\n",
              "      <td>[[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[The, asbestos, fiber, ,, crocidolite, ,, is, ...</td>\n",
              "      <td>[DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...</td>\n",
              "      <td>[[0.418, 0.24968, -0.41242, 0.1217, 0.34527, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-161caebd-5ea9-4e56-8a8a-a05d1cca5fa0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-161caebd-5ea9-4e56-8a8a-a05d1cca5fa0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-161caebd-5ea9-4e56-8a8a-a05d1cca5fa0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6d653c94-ac23-48b4-b88d-114cc7ae45a6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d653c94-ac23-48b4-b88d-114cc7ae45a6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6d653c94-ac23-48b4-b88d-114cc7ae45a6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataframe",
              "summary": "{\n  \"name\": \"dataframe\",\n  \"rows\": 3914,\n  \"fields\": [\n    {\n      \"column\": \"file_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49,\n        \"min\": 1,\n        \"max\": 199,\n        \"num_unique_values\": 199,\n        \"samples\": [\n          83,\n          16,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"features\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_num=50\n",
        "test_num=49\n",
        "\n",
        "len_doc = dataframe[\"file_id\"].nunique()\n",
        "\n",
        "df_train = None\n",
        "df_test = None\n",
        "df_val = None\n",
        "train_num = len_doc - test_num - val_num\n",
        "\n",
        "df_train = dataframe.loc[dataframe[\"file_id\"].isin(range(train_num + 1))]\n",
        "df_val = dataframe.loc[dataframe[\"file_id\"].isin(range(train_num + 1, train_num + val_num + 1))]\n",
        "df_test = dataframe.loc[dataframe[\"file_id\"].isin(range(train_num + val_num + 1, len_doc + 1))]\n",
        "\n",
        "print('Length of training dataset: ', len(df_train))\n",
        "print('Length of validation dataset: ', len(df_val))\n",
        "print('Length of testing dataset: ', len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inh22JXYoEek",
        "outputId": "8b57b580-c720-4f72-ea1d-1155996c6495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training dataset:  1963\n",
            "Length of validation dataset:  1299\n",
            "Length of testing dataset:  652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "MAX_LENGTH = len(max(df_train[\"sentence\"].tolist(), key = len))\n",
        "\n",
        "train_features_padded = pad_sequences(df_train[\"features\"].tolist(), maxlen = MAX_LENGTH, padding = \"post\", dtype = \"float32\")\n",
        "validation_features_padded = pad_sequences(df_val[\"features\"].tolist(), maxlen = MAX_LENGTH, padding = \"post\", dtype = \"float32\")\n",
        "test_features_padded = pad_sequences(df_test[\"features\"].tolist(), maxlen = MAX_LENGTH, padding = \"post\", dtype = \"float32\")\n",
        "\n",
        "print(f\"The maximum length is {MAX_LENGTH}, thus:\")\n",
        "print(f\" - The shape of train_features is: ({len(train_features_padded)}, {len(train_features_padded[0])}, {len(train_features_padded[0, 0])}).\")\n",
        "print(f\" - The shape of validation_features is: ({len(validation_features_padded)}, {len(validation_features_padded[0])}, {len(validation_features_padded[0, 0])}).\")\n",
        "print(f\" - The shape of test_features is: ({len(test_features_padded)}, {len(test_features_padded[0])}, {len(test_features_padded[0, 0])}).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU1H1_mJXP-k",
        "outputId": "7e8b88b7-caec-4f9d-bc1e-a9eebe073089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum length is 249, thus:\n",
            " - The shape of train_features is: (1963, 249, 50).\n",
            " - The shape of validation_features is: (1299, 249, 50).\n",
            " - The shape of test_features is: (652, 249, 50).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tags = [item for sublist in df_train[\"tags\"].tolist() for item in sublist]\n",
        "validation_tags = [item for sublist in df_val[\"tags\"].tolist() for item in sublist]\n",
        "test_tags = [item for sublist in df_train[\"tags\"].tolist() for item in sublist]\n",
        "\n",
        "tags = list(dict.fromkeys(train_tags))\n",
        "\n",
        "tag_to_index = {}\n",
        "tag_to_index[\"PAD\"] = 0\n",
        "for i, tag in enumerate(list(tags)):\n",
        "  tag_to_index[tag] = i + 1\n",
        "\n",
        "train_tags = [[tag_to_index[tag] for tag in tags_list] for tags_list in list(df_train[\"tags\"])]\n",
        "validation_tags = [[tag_to_index[tag] for tag in tags_list] for tags_list in list(df_val[\"tags\"])]\n",
        "test_tags = [[tag_to_index[tag] for tag in tags_list] for tags_list in list(df_test[\"tags\"])]\n",
        "\n",
        "\n",
        "train_tags_padded = pad_sequences(train_tags, maxlen = MAX_LENGTH, padding = \"post\")\n",
        "validation_tags_padded = pad_sequences(validation_tags, maxlen = MAX_LENGTH, padding = \"post\")\n",
        "test_tags_padded = pad_sequences(test_tags, maxlen = MAX_LENGTH, padding = \"post\")\n",
        "\n",
        "print(f\"The shape of train_tags is: ({len(train_tags_padded)}, {len(train_tags_padded[0])}).\")\n",
        "print(f\"The shape of validation_tags is: ({len(validation_tags_padded)}, {len(validation_tags_padded[0])}).\")\n",
        "print(f\"The shape of test_tags is: ({len(test_tags_padded)}, {len(test_tags_padded[0])}).\")\n",
        "\n",
        "test_counts = [test_tags.count(tag) for tag in tags]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkS33k_EaY5K",
        "outputId": "f390bdca-b219-4482-e542-bdba5ffa74a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of train_tags is: (1963, 249).\n",
            "The shape of validation_tags is: (1299, 249).\n",
            "The shape of test_tags is: (652, 249).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE5MdTDIUOBF"
      },
      "source": [
        "# [Task 2 - 0.5 points] Text encoding\n",
        "\n",
        "To train a neural POS tagger, you first need to encode text into numerical format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VimvZYs0UOBF"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Embed words using **GloVe embeddings**.\n",
        "* You are **free** to pick any embedding dimension.\n",
        "* [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation_tag_list = [\"PAD\", \",\", \".\", \"``\", \"''\", \":\", \"$\", \"-LRB-\", \"-RRB-\", \"SYM\", \"LS\", \"#\"]\n",
        "\n",
        "figures_path = os.path.join(os.getcwd(), \"figures\")\n",
        "if not os.path.exists(figures_path):\n",
        "  os.makedirs(figures_path)\n",
        "\n",
        "def plot_classes_distribution(classes, counts, filename, figures_path = figures_path):\n",
        "\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (9, 4))\n",
        "  bars = ax.bar(np.arange(0, len(classes), 1), counts)\n",
        "\n",
        "\n",
        "  for i in range(len(classes)):\n",
        "    if classes[i] in punctuation_tag_list: bars[i].set_alpha(0.5)\n",
        "\n",
        "  ax.set_xlabel(\"Class\")\n",
        "  ax.set_ylabel(\"Count\")\n",
        "  ax.set_yscale(\"log\")\n",
        "  ax.set_xticks(np.arange(0, len(classes), 1))\n",
        "  ax.set_xticklabels(classes, rotation = 90)\n",
        "\n",
        "  fig.savefig(f\"{figures_path}/{filename}_classes_distribution.pdf\", bbox_inches = \"tight\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "7s5rIMUavtpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJUtjpXbUOBF"
      },
      "source": [
        "# [Task 3 - 1.0 points] Model definition\n",
        "\n",
        "You are now tasked to define your neural POS tagger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt0PygGYUOBF"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
        "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
        "\n",
        "* **Model 1**: add an additional LSTM layer to the Baseline model.\n",
        "* **Model 2**: add an additional Dense layer to the Baseline model.\n",
        "\n",
        "* **Do not mix Model 1 and Model 2**. Each model has its own instructions.\n",
        "\n",
        "**Note**: if a document contains many tokens, you are **free** to split them into chunks or sentences to define your mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Bidirectional, LSTM, TimeDistributed, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "models_name = [\"m_0\", \"m_1\", \"m_2\"]\n",
        "descriptions_dict = {models_name[0]: (f\"Baseline model ({models_name[0]}): \\n\"\n",
        "                                      \" - Bi-directional LSTM layer. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - Softmax activation function.\"),\n",
        "                     models_name[1]: (f\"Additional bi-directional LSTM model ({models_name[1]}): \\n\"\n",
        "                                      \" - Bi-directional LSTM layer. \\n\"\n",
        "                                      \" - Bi-directional LSTM layer. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - Softmax activation function.\"),\n",
        "                     models_name[2]: (f\"Additional dense layer model ({models_name[2]}): \\n\"\n",
        "                                      \" - Bi-directional LSTM layer. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - ReLU activation function. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - Softmax activation function.\")}\n",
        "\n",
        "\n",
        "models = {}\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 100\n",
        "LR = 0.01\n",
        "REG = 0.01\n",
        "early_stopping = EarlyStopping(monitor = \"val_loss\", patience = 5, restore_best_weights = True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = \"val_loss\", patience = 3, factor = 0.1)\n",
        "\n",
        "\n",
        "def get_model(name, layers, input_shape):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(InputLayer(input_shape = input_shape))\n",
        "  for layer in layers:\n",
        "    model.add(layer)\n",
        "  model.add(TimeDistributed(Dense(len(tag_to_index), activation = \"softmax\")))\n",
        "  model._name = name\n",
        "\n",
        "\n",
        "  return model\n",
        "\n",
        "def grid_search(model_name, units, best_baseline_LSTM_units = None):\n",
        "\n",
        "\n",
        "  models = []\n",
        "  histories = []\n",
        "\n",
        "  print(f\"Grid-search, {model_name} model.\")\n",
        "\n",
        "\n",
        "  for n in units:\n",
        "    if model_name == \"m_0\":\n",
        "      layers = [Bidirectional(LSTM(n, return_sequences = True, recurrent_regularizer = l2(REG)))]\n",
        "    elif model_name == \"m_1\" and best_baseline_LSTM_units != None:\n",
        "      layers = [Bidirectional(LSTM(best_baseline_LSTM_units, return_sequences = True, recurrent_regularizer = l2(REG))),\n",
        "                Bidirectional(LSTM(n, return_sequences = True, recurrent_regularizer = l2(REG)))]\n",
        "    elif model_name == \"m_2\" and best_baseline_LSTM_units != None:\n",
        "      layers = [Bidirectional(LSTM(best_baseline_LSTM_units, return_sequences = True, recurrent_regularizer = l2(REG))),\n",
        "                TimeDistributed(Dense(n, activation = \"relu\"))]\n",
        "\n",
        "    model = get_model(name = model_name, layers = layers, input_shape = (MAX_LENGTH, EMBEDDING_DIMENSION))\n",
        "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = Adam(LR), metrics = [\"accuracy\"])\n",
        "    models.append(model)\n",
        "    print(f\"\\nNumber of units: {n}.\\n\")\n",
        "    models[-1].summary()\n",
        "\n",
        "\n",
        "    history = models[-1].fit(train_features_padded, train_tags_padded, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data = (validation_features_padded, validation_tags_padded), callbacks = [early_stopping, reduce_lr])\n",
        "    histories.append(history)\n",
        "\n",
        "\n",
        "  return models, histories"
      ],
      "metadata": {
        "id": "HiAzGpu0cxF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ25tiWbUOBF"
      },
      "source": [
        "# [Task 4 - 1.0 points] Metrics\n",
        "\n",
        "Before training the models, you are tasked to define the evaluation metrics for comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVK-mg4kUOBG"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Evaluate your models using macro F1-score, compute over **all** tokens.\n",
        "* **Concatenate** all tokens in a data split to compute the F1-score. (**Hint**: accumulate FP, TP, FN, TN iteratively)\n",
        "* **Do not consider punctuation and symbol classes** $\\rightarrow$ [What is punctuation?](https://en.wikipedia.org/wiki/English_punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation_tag_list = [\"PAD\", \",\", \".\", \"``\", \"''\", \":\", \"$\", \"-LRB-\", \"-RRB-\", \"SYM\", \"LS\", \"#\"]"
      ],
      "metadata": {
        "id": "p5lPkxCehErA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_F1_score(model, X, y, tag_to_index_vocabulary):\n",
        "\n",
        "  pred = model.predict(X)\n",
        "  report = classification_report(y.flatten(),\n",
        "                                 np.argmax(pred, axis = 2).flatten(),\n",
        "                                 labels = np.arange(0, len(tag_to_index_vocabulary), 1),\n",
        "                                 target_names = list(tag_to_index_vocabulary.keys()),\n",
        "                                 zero_division = 0,\n",
        "                                 output_dict = True)\n",
        "\n",
        "  macro_f1 = 0\n",
        "  for tag in list(tag_to_index_vocabulary.keys()):\n",
        "    if tag not in punctuation_tag_list:\n",
        "      macro_f1 = macro_f1 + report[tag][\"f1-score\"]\n",
        "  macro_f1 = macro_f1 / (len(list(tag_to_index_vocabulary.keys())) - len(punctuation_tag_list))\n",
        "  return macro_f1, pred, report\n",
        "\n",
        "def get_best_model(models, units):\n",
        "\n",
        "  f1_scores = [compute_F1_score(model, validation_features_padded, validation_tags_padded, tag_to_index)[0] for model in models]\n",
        "  best = units[np.argmax(f1_scores)]\n",
        "  print(f\"The best number of units is: {best}.\")\n",
        "\n",
        "  return best, f1_scores, models[np.argmax(f1_scores)]"
      ],
      "metadata": {
        "id": "w55YLzkUg_ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9_zSbLaUOBH"
      },
      "source": [
        "# [Task 5 - 1.0 points] Training and Evaluation\n",
        "\n",
        "You are now tasked to train and evaluate the Baseline, Model 1, and Model 2."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_units = [32, 64, 128, 256]\n",
        "baseline_models, baseline_model_histories = grid_search(models_name[0], baseline_units)"
      ],
      "metadata": {
        "id": "-WJuAVc9fjLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd869f67-665a-4c3d-81ed-08a535974ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid-search, m_0 model.\n",
            "\n",
            "Number of units: 32.\n",
            "\n",
            "Model: \"m_0\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirection  (None, 249, 64)           21248     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 249, 46)           2990      \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24238 (94.68 KB)\n",
            "Trainable params: 24238 (94.68 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 7s 95ms/step - loss: 1.9025 - accuracy: 0.8914 - val_loss: 0.5833 - val_accuracy: 0.9308 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.5033 - accuracy: 0.9400 - val_loss: 0.3987 - val_accuracy: 0.9488 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.3326 - accuracy: 0.9502 - val_loss: 0.2665 - val_accuracy: 0.9530 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.2282 - accuracy: 0.9576 - val_loss: 0.1930 - val_accuracy: 0.9616 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.1703 - accuracy: 0.9659 - val_loss: 0.1538 - val_accuracy: 0.9672 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.1386 - accuracy: 0.9703 - val_loss: 0.1306 - val_accuracy: 0.9701 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.1183 - accuracy: 0.9729 - val_loss: 0.1148 - val_accuracy: 0.9728 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.1038 - accuracy: 0.9758 - val_loss: 0.1030 - val_accuracy: 0.9754 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0927 - accuracy: 0.9781 - val_loss: 0.0936 - val_accuracy: 0.9771 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0839 - accuracy: 0.9797 - val_loss: 0.0862 - val_accuracy: 0.9784 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0767 - accuracy: 0.9811 - val_loss: 0.0803 - val_accuracy: 0.9796 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0709 - accuracy: 0.9823 - val_loss: 0.0755 - val_accuracy: 0.9806 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0659 - accuracy: 0.9833 - val_loss: 0.0713 - val_accuracy: 0.9816 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0618 - accuracy: 0.9842 - val_loss: 0.0680 - val_accuracy: 0.9823 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0583 - accuracy: 0.9849 - val_loss: 0.0652 - val_accuracy: 0.9828 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0552 - accuracy: 0.9856 - val_loss: 0.0628 - val_accuracy: 0.9832 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0525 - accuracy: 0.9862 - val_loss: 0.0607 - val_accuracy: 0.9839 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0500 - accuracy: 0.9869 - val_loss: 0.0588 - val_accuracy: 0.9843 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0479 - accuracy: 0.9875 - val_loss: 0.0572 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0459 - accuracy: 0.9879 - val_loss: 0.0558 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0442 - accuracy: 0.9884 - val_loss: 0.0546 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0425 - accuracy: 0.9888 - val_loss: 0.0535 - val_accuracy: 0.9854 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0411 - accuracy: 0.9892 - val_loss: 0.0525 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0396 - accuracy: 0.9895 - val_loss: 0.0514 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0384 - accuracy: 0.9898 - val_loss: 0.0507 - val_accuracy: 0.9861 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0372 - accuracy: 0.9901 - val_loss: 0.0500 - val_accuracy: 0.9861 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0361 - accuracy: 0.9903 - val_loss: 0.0492 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0350 - accuracy: 0.9908 - val_loss: 0.0487 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0340 - accuracy: 0.9909 - val_loss: 0.0481 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0331 - accuracy: 0.9911 - val_loss: 0.0476 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0323 - accuracy: 0.9913 - val_loss: 0.0472 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0315 - accuracy: 0.9915 - val_loss: 0.0470 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0308 - accuracy: 0.9917 - val_loss: 0.0464 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0300 - accuracy: 0.9919 - val_loss: 0.0462 - val_accuracy: 0.9871 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0294 - accuracy: 0.9921 - val_loss: 0.0459 - val_accuracy: 0.9871 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0288 - accuracy: 0.9923 - val_loss: 0.0455 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0281 - accuracy: 0.9925 - val_loss: 0.0453 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0275 - accuracy: 0.9926 - val_loss: 0.0450 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0269 - accuracy: 0.9928 - val_loss: 0.0448 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0263 - accuracy: 0.9930 - val_loss: 0.0445 - val_accuracy: 0.9876 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 0.0444 - val_accuracy: 0.9875 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0254 - accuracy: 0.9932 - val_loss: 0.0441 - val_accuracy: 0.9877 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.0440 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0244 - accuracy: 0.9935 - val_loss: 0.0439 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0437 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0236 - accuracy: 0.9937 - val_loss: 0.0437 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.0436 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.0435 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0224 - accuracy: 0.9940 - val_loss: 0.0434 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.0433 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 0.0433 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0214 - accuracy: 0.9943 - val_loss: 0.0432 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.0431 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0430 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0203 - accuracy: 0.9946 - val_loss: 0.0430 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0200 - accuracy: 0.9946 - val_loss: 0.0428 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0197 - accuracy: 0.9948 - val_loss: 0.0431 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.0429 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0191 - accuracy: 0.9949 - val_loss: 0.0431 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.0429 - val_accuracy: 0.9883 - lr: 1.0000e-03\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 0.0429 - val_accuracy: 0.9884 - lr: 1.0000e-03\n",
            "\n",
            "Number of units: 64.\n",
            "\n",
            "Model: \"m_0\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_1 (Bidirecti  (None, 249, 128)          58880     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDi  (None, 249, 46)           5934      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64814 (253.18 KB)\n",
            "Trainable params: 64814 (253.18 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 4s 95ms/step - loss: 1.6339 - accuracy: 0.8980 - val_loss: 0.5791 - val_accuracy: 0.9410 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.4690 - accuracy: 0.9464 - val_loss: 0.3464 - val_accuracy: 0.9518 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.2753 - accuracy: 0.9579 - val_loss: 0.2095 - val_accuracy: 0.9629 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.1731 - accuracy: 0.9669 - val_loss: 0.1455 - val_accuracy: 0.9695 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.1266 - accuracy: 0.9724 - val_loss: 0.1160 - val_accuracy: 0.9727 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.1031 - accuracy: 0.9757 - val_loss: 0.0990 - val_accuracy: 0.9756 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.0881 - accuracy: 0.9786 - val_loss: 0.0875 - val_accuracy: 0.9779 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.0774 - accuracy: 0.9807 - val_loss: 0.0788 - val_accuracy: 0.9797 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0691 - accuracy: 0.9825 - val_loss: 0.0721 - val_accuracy: 0.9809 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 32ms/step - loss: 0.0625 - accuracy: 0.9839 - val_loss: 0.0668 - val_accuracy: 0.9821 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0572 - accuracy: 0.9851 - val_loss: 0.0625 - val_accuracy: 0.9830 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0527 - accuracy: 0.9862 - val_loss: 0.0590 - val_accuracy: 0.9838 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 32ms/step - loss: 0.0488 - accuracy: 0.9870 - val_loss: 0.0559 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0455 - accuracy: 0.9878 - val_loss: 0.0534 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 32ms/step - loss: 0.0427 - accuracy: 0.9885 - val_loss: 0.0513 - val_accuracy: 0.9855 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0402 - accuracy: 0.9891 - val_loss: 0.0494 - val_accuracy: 0.9860 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.0379 - accuracy: 0.9897 - val_loss: 0.0480 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0360 - accuracy: 0.9902 - val_loss: 0.0465 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 32ms/step - loss: 0.0342 - accuracy: 0.9907 - val_loss: 0.0455 - val_accuracy: 0.9869 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 32ms/step - loss: 0.0326 - accuracy: 0.9911 - val_loss: 0.0445 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.0310 - accuracy: 0.9917 - val_loss: 0.0434 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 0.0427 - val_accuracy: 0.9877 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.0282 - accuracy: 0.9925 - val_loss: 0.0419 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0270 - accuracy: 0.9928 - val_loss: 0.0412 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 32ms/step - loss: 0.0260 - accuracy: 0.9931 - val_loss: 0.0410 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.0403 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0400 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.0397 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.0392 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0214 - accuracy: 0.9944 - val_loss: 0.0390 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0207 - accuracy: 0.9946 - val_loss: 0.0390 - val_accuracy: 0.9888 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.0386 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0192 - accuracy: 0.9950 - val_loss: 0.0384 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.0384 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.0383 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0174 - accuracy: 0.9955 - val_loss: 0.0379 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.0381 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.0380 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0157 - accuracy: 0.9960 - val_loss: 0.0377 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.0379 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0381 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.0378 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.0375 - val_accuracy: 0.9894 - lr: 1.0000e-03\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0133 - accuracy: 0.9967 - val_loss: 0.0375 - val_accuracy: 0.9893 - lr: 1.0000e-03\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.0376 - val_accuracy: 0.9894 - lr: 1.0000e-03\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.0375 - val_accuracy: 0.9893 - lr: 1.0000e-03\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.0375 - val_accuracy: 0.9893 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.0375 - val_accuracy: 0.9893 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 32ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.0375 - val_accuracy: 0.9893 - lr: 1.0000e-04\n",
            "\n",
            "Number of units: 128.\n",
            "\n",
            "Model: \"m_0\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirecti  (None, 249, 256)          183296    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDi  (None, 249, 46)           11822     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 195118 (762.18 KB)\n",
            "Trainable params: 195118 (762.18 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 106ms/step - loss: 1.7870 - accuracy: 0.9029 - val_loss: 0.7510 - val_accuracy: 0.9481 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.5647 - accuracy: 0.9544 - val_loss: 0.3820 - val_accuracy: 0.9613 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.2892 - accuracy: 0.9666 - val_loss: 0.2084 - val_accuracy: 0.9690 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.1652 - accuracy: 0.9731 - val_loss: 0.1322 - val_accuracy: 0.9741 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.1104 - accuracy: 0.9772 - val_loss: 0.0988 - val_accuracy: 0.9771 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0846 - accuracy: 0.9800 - val_loss: 0.0815 - val_accuracy: 0.9797 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0701 - accuracy: 0.9828 - val_loss: 0.0711 - val_accuracy: 0.9817 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0606 - accuracy: 0.9846 - val_loss: 0.0639 - val_accuracy: 0.9831 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0533 - accuracy: 0.9865 - val_loss: 0.0582 - val_accuracy: 0.9845 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0475 - accuracy: 0.9877 - val_loss: 0.0540 - val_accuracy: 0.9854 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0427 - accuracy: 0.9888 - val_loss: 0.0505 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0389 - accuracy: 0.9896 - val_loss: 0.0476 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0357 - accuracy: 0.9904 - val_loss: 0.0455 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 0.0439 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0304 - accuracy: 0.9919 - val_loss: 0.0423 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0282 - accuracy: 0.9925 - val_loss: 0.0414 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0264 - accuracy: 0.9930 - val_loss: 0.0406 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0247 - accuracy: 0.9936 - val_loss: 0.0396 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0232 - accuracy: 0.9940 - val_loss: 0.0387 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0217 - accuracy: 0.9944 - val_loss: 0.0380 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 0.0376 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 0.0372 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.0375 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0173 - accuracy: 0.9956 - val_loss: 0.0371 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.0362 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.0364 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.0364 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 0.0365 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 0.0359 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.0357 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.0357 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.0357 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.0357 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0116 - accuracy: 0.9975 - val_loss: 0.0357 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 0.0357 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 0.0357 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 0.0357 - val_accuracy: 0.9899 - lr: 1.0000e-05\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 0.0357 - val_accuracy: 0.9899 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 256.\n",
            "\n",
            "Model: \"m_0\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_3 (Bidirecti  (None, 249, 512)          628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDi  (None, 249, 46)           23598     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 652334 (2.49 MB)\n",
            "Trainable params: 652334 (2.49 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 145ms/step - loss: 2.4242 - accuracy: 0.8784 - val_loss: 1.4346 - val_accuracy: 0.9364 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 1.0623 - accuracy: 0.9484 - val_loss: 0.5873 - val_accuracy: 0.9575 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.3879 - accuracy: 0.9640 - val_loss: 0.2299 - val_accuracy: 0.9684 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.1696 - accuracy: 0.9723 - val_loss: 0.1275 - val_accuracy: 0.9738 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.1054 - accuracy: 0.9766 - val_loss: 0.0948 - val_accuracy: 0.9767 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0818 - accuracy: 0.9798 - val_loss: 0.0797 - val_accuracy: 0.9794 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0694 - accuracy: 0.9823 - val_loss: 0.0707 - val_accuracy: 0.9813 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0612 - accuracy: 0.9842 - val_loss: 0.0645 - val_accuracy: 0.9826 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0546 - accuracy: 0.9857 - val_loss: 0.0591 - val_accuracy: 0.9841 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0493 - accuracy: 0.9870 - val_loss: 0.0556 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0451 - accuracy: 0.9881 - val_loss: 0.0518 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0414 - accuracy: 0.9890 - val_loss: 0.0491 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0382 - accuracy: 0.9898 - val_loss: 0.0468 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0354 - accuracy: 0.9906 - val_loss: 0.0447 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0329 - accuracy: 0.9911 - val_loss: 0.0434 - val_accuracy: 0.9876 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0309 - accuracy: 0.9917 - val_loss: 0.0418 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 0.0405 - val_accuracy: 0.9884 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0271 - accuracy: 0.9929 - val_loss: 0.0396 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0253 - accuracy: 0.9934 - val_loss: 0.0387 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0239 - accuracy: 0.9939 - val_loss: 0.0377 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.0373 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0212 - accuracy: 0.9947 - val_loss: 0.0368 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.0364 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 0.0359 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0180 - accuracy: 0.9956 - val_loss: 0.0359 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 0.0353 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0163 - accuracy: 0.9961 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.0350 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.0348 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0140 - accuracy: 0.9967 - val_loss: 0.0356 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0349 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0126 - accuracy: 0.9972 - val_loss: 0.0351 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.0342 - val_accuracy: 0.9901 - lr: 1.0000e-03\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 0.0342 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.0341 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.0341 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0341 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0342 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0342 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0341 - val_accuracy: 0.9902 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0341 - val_accuracy: 0.9902 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_best_units, baseline_f1_scores, models[models_name[0]] = get_best_model(baseline_models, baseline_units)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KygnMbTCg42U",
        "outputId": "39e5636b-22a9-4ec7-d4c3-ad279cd38ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 7ms/step\n",
            "41/41 [==============================] - 1s 7ms/step\n",
            "41/41 [==============================] - 1s 7ms/step\n",
            "41/41 [==============================] - 1s 10ms/step\n",
            "The best number of units is: 256.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "double_lstm_units = [32, 64, 128, 256]\n",
        "double_lstm_models, double_lstm_model_histories = grid_search(models_name[1], double_lstm_units, baseline_best_units)\n"
      ],
      "metadata": {
        "id": "VmMBsGa_l1YE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de501d9d-ae6f-40ae-824d-19bf67e9a521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid-search, m_1 model.\n",
            "\n",
            "Number of units: 32.\n",
            "\n",
            "Model: \"m_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_4 (Bidirecti  (None, 249, 512)          628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirecti  (None, 249, 64)           139520    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDi  (None, 249, 46)           2990      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 771246 (2.94 MB)\n",
            "Trainable params: 771246 (2.94 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 8s 210ms/step - loss: 2.4682 - accuracy: 0.8829 - val_loss: 0.7607 - val_accuracy: 0.9156 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.5131 - accuracy: 0.9245 - val_loss: 0.3434 - val_accuracy: 0.9337 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.2767 - accuracy: 0.9414 - val_loss: 0.2178 - val_accuracy: 0.9487 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.1855 - accuracy: 0.9545 - val_loss: 0.1611 - val_accuracy: 0.9582 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.1398 - accuracy: 0.9644 - val_loss: 0.1273 - val_accuracy: 0.9669 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.1119 - accuracy: 0.9711 - val_loss: 0.1054 - val_accuracy: 0.9721 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0925 - accuracy: 0.9757 - val_loss: 0.0896 - val_accuracy: 0.9761 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0776 - accuracy: 0.9797 - val_loss: 0.0771 - val_accuracy: 0.9795 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0656 - accuracy: 0.9830 - val_loss: 0.0678 - val_accuracy: 0.9822 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0562 - accuracy: 0.9854 - val_loss: 0.0608 - val_accuracy: 0.9835 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0492 - accuracy: 0.9872 - val_loss: 0.0564 - val_accuracy: 0.9847 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0438 - accuracy: 0.9886 - val_loss: 0.0525 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0391 - accuracy: 0.9900 - val_loss: 0.0473 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0343 - accuracy: 0.9914 - val_loss: 0.0450 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0312 - accuracy: 0.9922 - val_loss: 0.0431 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.0277 - accuracy: 0.9931 - val_loss: 0.0434 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0255 - accuracy: 0.9938 - val_loss: 0.0408 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0226 - accuracy: 0.9945 - val_loss: 0.0397 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 0.0389 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.0190 - accuracy: 0.9956 - val_loss: 0.0380 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 0.0367 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 0.0367 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.0366 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.0365 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.0358 - val_accuracy: 0.9905 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0106 - accuracy: 0.9978 - val_loss: 0.0366 - val_accuracy: 0.9903 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.0371 - val_accuracy: 0.9903 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.0365 - val_accuracy: 0.9905 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0353 - val_accuracy: 0.9906 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0353 - val_accuracy: 0.9906 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0352 - val_accuracy: 0.9906 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.0354 - val_accuracy: 0.9906 - lr: 1.0000e-03\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.0353 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.0353 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.0353 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.0353 - val_accuracy: 0.9906 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 64.\n",
            "\n",
            "Model: \"m_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_6 (Bidirecti  (None, 249, 512)          628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirecti  (None, 249, 128)          295424    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDi  (None, 249, 46)           5934      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 930094 (3.55 MB)\n",
            "Trainable params: 930094 (3.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 9s 219ms/step - loss: 2.4984 - accuracy: 0.8895 - val_loss: 0.7830 - val_accuracy: 0.9243 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.5107 - accuracy: 0.9294 - val_loss: 0.3249 - val_accuracy: 0.9415 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.2522 - accuracy: 0.9478 - val_loss: 0.1919 - val_accuracy: 0.9543 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.1598 - accuracy: 0.9607 - val_loss: 0.1359 - val_accuracy: 0.9639 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.1170 - accuracy: 0.9687 - val_loss: 0.1059 - val_accuracy: 0.9703 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0929 - accuracy: 0.9742 - val_loss: 0.0887 - val_accuracy: 0.9752 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0776 - accuracy: 0.9786 - val_loss: 0.0766 - val_accuracy: 0.9787 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0660 - accuracy: 0.9819 - val_loss: 0.0679 - val_accuracy: 0.9812 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0570 - accuracy: 0.9844 - val_loss: 0.0603 - val_accuracy: 0.9833 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0495 - accuracy: 0.9866 - val_loss: 0.0554 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0438 - accuracy: 0.9882 - val_loss: 0.0518 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0395 - accuracy: 0.9892 - val_loss: 0.0484 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0354 - accuracy: 0.9904 - val_loss: 0.0450 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0314 - accuracy: 0.9917 - val_loss: 0.0426 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0281 - accuracy: 0.9927 - val_loss: 0.0423 - val_accuracy: 0.9884 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0252 - accuracy: 0.9934 - val_loss: 0.0394 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0222 - accuracy: 0.9943 - val_loss: 0.0387 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0202 - accuracy: 0.9949 - val_loss: 0.0376 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0182 - accuracy: 0.9955 - val_loss: 0.0387 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.0376 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0155 - accuracy: 0.9962 - val_loss: 0.0372 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0363 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.0367 - val_accuracy: 0.9899 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0113 - accuracy: 0.9975 - val_loss: 0.0383 - val_accuracy: 0.9899 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0371 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0356 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.0354 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.0355 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.0354 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0356 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 128.\n",
            "\n",
            "Model: \"m_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_8 (Bidirecti  (None, 249, 512)          628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirecti  (None, 249, 256)          656384    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDi  (None, 249, 46)           11822     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1296942 (4.95 MB)\n",
            "Trainable params: 1296942 (4.95 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 9s 241ms/step - loss: 3.2734 - accuracy: 0.9008 - val_loss: 1.6241 - val_accuracy: 0.9282 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.9767 - accuracy: 0.9346 - val_loss: 0.4909 - val_accuracy: 0.9467 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.3356 - accuracy: 0.9531 - val_loss: 0.2142 - val_accuracy: 0.9600 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 0.1656 - accuracy: 0.9658 - val_loss: 0.1294 - val_accuracy: 0.9696 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.1085 - accuracy: 0.9737 - val_loss: 0.0976 - val_accuracy: 0.9742 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.0829 - accuracy: 0.9784 - val_loss: 0.0780 - val_accuracy: 0.9791 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.0671 - accuracy: 0.9822 - val_loss: 0.0664 - val_accuracy: 0.9818 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.0566 - accuracy: 0.9848 - val_loss: 0.0586 - val_accuracy: 0.9835 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 0.0488 - accuracy: 0.9867 - val_loss: 0.0529 - val_accuracy: 0.9851 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.0422 - accuracy: 0.9886 - val_loss: 0.0502 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.0381 - accuracy: 0.9896 - val_loss: 0.0459 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.0333 - accuracy: 0.9909 - val_loss: 0.0431 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 0.0297 - accuracy: 0.9919 - val_loss: 0.0418 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 0.0262 - accuracy: 0.9930 - val_loss: 0.0395 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 152ms/step - loss: 0.0238 - accuracy: 0.9937 - val_loss: 0.0384 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.0384 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 152ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.0375 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 152ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.0359 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: 0.0369 - val_accuracy: 0.9899 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 0.0362 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 0.0345 - val_accuracy: 0.9906 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0343 - val_accuracy: 0.9907 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.0350 - val_accuracy: 0.9907 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 0.0360 - val_accuracy: 0.9904 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0384 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0348 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0340 - val_accuracy: 0.9909 - lr: 1.0000e-03\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0341 - val_accuracy: 0.9909 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0340 - val_accuracy: 0.9909 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.0341 - val_accuracy: 0.9909 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.0341 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.0342 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
            "\n",
            "Number of units: 256.\n",
            "\n",
            "Model: \"m_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_10 (Bidirect  (None, 249, 512)          628736    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirect  (None, 249, 512)          1574912   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDi  (None, 249, 46)           23598     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2227246 (8.50 MB)\n",
            "Trainable params: 2227246 (8.50 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 11s 309ms/step - loss: 4.0328 - accuracy: 0.8281 - val_loss: 1.7218 - val_accuracy: 0.9203 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.9920 - accuracy: 0.9241 - val_loss: 0.5053 - val_accuracy: 0.9312 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.3607 - accuracy: 0.9381 - val_loss: 0.2477 - val_accuracy: 0.9467 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.2017 - accuracy: 0.9523 - val_loss: 0.1646 - val_accuracy: 0.9566 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.1424 - accuracy: 0.9619 - val_loss: 0.1291 - val_accuracy: 0.9636 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.1139 - accuracy: 0.9684 - val_loss: 0.1086 - val_accuracy: 0.9698 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.0958 - accuracy: 0.9732 - val_loss: 0.0923 - val_accuracy: 0.9736 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.0817 - accuracy: 0.9766 - val_loss: 0.0812 - val_accuracy: 0.9765 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.0717 - accuracy: 0.9794 - val_loss: 0.0735 - val_accuracy: 0.9785 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.0632 - accuracy: 0.9821 - val_loss: 0.0673 - val_accuracy: 0.9810 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.0565 - accuracy: 0.9842 - val_loss: 0.0600 - val_accuracy: 0.9833 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.0504 - accuracy: 0.9860 - val_loss: 0.0585 - val_accuracy: 0.9828 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.0465 - accuracy: 0.9870 - val_loss: 0.0536 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.0418 - accuracy: 0.9885 - val_loss: 0.0499 - val_accuracy: 0.9860 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.0372 - accuracy: 0.9899 - val_loss: 0.0462 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.0338 - accuracy: 0.9908 - val_loss: 0.0449 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.0433 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.0290 - accuracy: 0.9922 - val_loss: 0.0414 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.0264 - accuracy: 0.9931 - val_loss: 0.0429 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0402 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.0386 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.0204 - accuracy: 0.9948 - val_loss: 0.0373 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.0376 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.0369 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.0366 - val_accuracy: 0.9899 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.0360 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0371 - val_accuracy: 0.9899 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 0.0367 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.0113 - accuracy: 0.9975 - val_loss: 0.0380 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.0349 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.0350 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.0348 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.0348 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.0349 - val_accuracy: 0.9905 - lr: 1.0000e-03\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.0348 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0349 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0349 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0349 - val_accuracy: 0.9904 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, double_lstm_f1_scores, models[models_name[1]] = get_best_model(double_lstm_models, double_lstm_units)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyh3GMV_peEy",
        "outputId": "43ae238b-6a7a-48f0-b6a1-5a8949119768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 2s 16ms/step\n",
            "41/41 [==============================] - 2s 20ms/step\n",
            "41/41 [==============================] - 2s 21ms/step\n",
            "41/41 [==============================] - 2s 27ms/step\n",
            "The best number of units is: 128.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "double_dense_units = [32, 64, 128, 256]\n",
        "double_dense_models, double_dense_model_histories = grid_search(models_name[2], double_dense_units, baseline_best_units)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPkvxPmSl4t-",
        "outputId": "b24898f9-67b5-4ddb-d5fb-c6cfd469d946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid-search, m_2 model.\n",
            "\n",
            "Number of units: 32.\n",
            "\n",
            "Model: \"m_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_12 (Bidirect  (None, 249, 512)          628736    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDi  (None, 249, 32)           16416     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_9 (TimeDi  (None, 249, 46)           1518      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 646670 (2.47 MB)\n",
            "Trainable params: 646670 (2.47 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 6s 145ms/step - loss: 2.3351 - accuracy: 0.8945 - val_loss: 0.8299 - val_accuracy: 0.9367 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.5079 - accuracy: 0.9451 - val_loss: 0.2762 - val_accuracy: 0.9521 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.2024 - accuracy: 0.9591 - val_loss: 0.1482 - val_accuracy: 0.9674 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.1193 - accuracy: 0.9707 - val_loss: 0.1009 - val_accuracy: 0.9731 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0860 - accuracy: 0.9766 - val_loss: 0.0811 - val_accuracy: 0.9777 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0689 - accuracy: 0.9805 - val_loss: 0.0703 - val_accuracy: 0.9798 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0583 - accuracy: 0.9836 - val_loss: 0.0618 - val_accuracy: 0.9824 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0506 - accuracy: 0.9858 - val_loss: 0.0568 - val_accuracy: 0.9839 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0449 - accuracy: 0.9873 - val_loss: 0.0531 - val_accuracy: 0.9851 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0412 - accuracy: 0.9884 - val_loss: 0.0501 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 0.0469 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0333 - accuracy: 0.9908 - val_loss: 0.0464 - val_accuracy: 0.9871 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0310 - accuracy: 0.9914 - val_loss: 0.0454 - val_accuracy: 0.9871 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0284 - accuracy: 0.9923 - val_loss: 0.0432 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 0.0418 - val_accuracy: 0.9884 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0245 - accuracy: 0.9934 - val_loss: 0.0430 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.0410 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0203 - accuracy: 0.9946 - val_loss: 0.0411 - val_accuracy: 0.9888 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.0407 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.0403 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.0395 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 0.0400 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0401 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.0413 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0099 - accuracy: 0.9977 - val_loss: 0.0387 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.0384 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.0384 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 0.0384 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 0.0384 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0385 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0385 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
            "\n",
            "Number of units: 64.\n",
            "\n",
            "Model: \"m_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_13 (Bidirect  (None, 249, 512)          628736    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " time_distributed_10 (TimeD  (None, 249, 64)           32832     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_11 (TimeD  (None, 249, 46)           2990      \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664558 (2.54 MB)\n",
            "Trainable params: 664558 (2.54 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 145ms/step - loss: 3.1124 - accuracy: 0.8425 - val_loss: 2.0139 - val_accuracy: 0.9228 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 1.4026 - accuracy: 0.9326 - val_loss: 0.8603 - val_accuracy: 0.9435 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.6123 - accuracy: 0.9508 - val_loss: 0.3950 - val_accuracy: 0.9588 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.2985 - accuracy: 0.9637 - val_loss: 0.2210 - val_accuracy: 0.9665 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1788 - accuracy: 0.9698 - val_loss: 0.1499 - val_accuracy: 0.9716 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1260 - accuracy: 0.9740 - val_loss: 0.1131 - val_accuracy: 0.9745 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0976 - accuracy: 0.9772 - val_loss: 0.0935 - val_accuracy: 0.9767 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0806 - accuracy: 0.9797 - val_loss: 0.0799 - val_accuracy: 0.9789 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0688 - accuracy: 0.9818 - val_loss: 0.0706 - val_accuracy: 0.9807 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0596 - accuracy: 0.9839 - val_loss: 0.0638 - val_accuracy: 0.9820 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0528 - accuracy: 0.9855 - val_loss: 0.0594 - val_accuracy: 0.9833 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0475 - accuracy: 0.9868 - val_loss: 0.0548 - val_accuracy: 0.9844 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0435 - accuracy: 0.9879 - val_loss: 0.0523 - val_accuracy: 0.9853 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0395 - accuracy: 0.9891 - val_loss: 0.0491 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0363 - accuracy: 0.9897 - val_loss: 0.0473 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0341 - accuracy: 0.9904 - val_loss: 0.0464 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.0455 - val_accuracy: 0.9871 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0295 - accuracy: 0.9916 - val_loss: 0.0450 - val_accuracy: 0.9871 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0275 - accuracy: 0.9922 - val_loss: 0.0427 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0255 - accuracy: 0.9929 - val_loss: 0.0436 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 0.0421 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 0.0419 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0211 - accuracy: 0.9941 - val_loss: 0.0414 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0201 - accuracy: 0.9944 - val_loss: 0.0406 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.0421 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.0409 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.0409 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.0392 - val_accuracy: 0.9893 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.0392 - val_accuracy: 0.9894 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.0391 - val_accuracy: 0.9895 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.0391 - val_accuracy: 0.9895 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.0391 - val_accuracy: 0.9895 - lr: 1.0000e-03\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.0391 - val_accuracy: 0.9895 - lr: 1.0000e-03\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.0391 - val_accuracy: 0.9895 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.0391 - val_accuracy: 0.9895 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.0391 - val_accuracy: 0.9895 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.0391 - val_accuracy: 0.9895 - lr: 1.0000e-05\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.0391 - val_accuracy: 0.9895 - lr: 1.0000e-05\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.0391 - val_accuracy: 0.9895 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 128.\n",
            "\n",
            "Model: \"m_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_14 (Bidirect  (None, 249, 512)          628736    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " time_distributed_12 (TimeD  (None, 249, 128)          65664     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_13 (TimeD  (None, 249, 46)           5934      \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 700334 (2.67 MB)\n",
            "Trainable params: 700334 (2.67 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 6s 148ms/step - loss: 2.2033 - accuracy: 0.9006 - val_loss: 0.7994 - val_accuracy: 0.9410 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.4701 - accuracy: 0.9520 - val_loss: 0.2454 - val_accuracy: 0.9623 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1654 - accuracy: 0.9691 - val_loss: 0.1157 - val_accuracy: 0.9726 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0908 - accuracy: 0.9768 - val_loss: 0.0813 - val_accuracy: 0.9771 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0670 - accuracy: 0.9810 - val_loss: 0.0650 - val_accuracy: 0.9811 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0541 - accuracy: 0.9844 - val_loss: 0.0569 - val_accuracy: 0.9837 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0471 - accuracy: 0.9865 - val_loss: 0.0544 - val_accuracy: 0.9844 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0417 - accuracy: 0.9878 - val_loss: 0.0490 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0373 - accuracy: 0.9892 - val_loss: 0.0465 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0335 - accuracy: 0.9904 - val_loss: 0.0446 - val_accuracy: 0.9871 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.0437 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0273 - accuracy: 0.9923 - val_loss: 0.0422 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0247 - accuracy: 0.9930 - val_loss: 0.0404 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 0.0397 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.0391 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.0401 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.0383 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.0379 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.0401 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.0387 - val_accuracy: 0.9899 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.0393 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0369 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.0367 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0368 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0369 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0369 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0369 - val_accuracy: 0.9902 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0368 - val_accuracy: 0.9903 - lr: 1.0000e-04\n",
            "\n",
            "Number of units: 256.\n",
            "\n",
            "Model: \"m_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_15 (Bidirect  (None, 249, 512)          628736    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " time_distributed_14 (TimeD  (None, 249, 256)          131328    \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_15 (TimeD  (None, 249, 46)           11822     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 771886 (2.94 MB)\n",
            "Trainable params: 771886 (2.94 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 6s 151ms/step - loss: 3.6433 - accuracy: 0.8336 - val_loss: 1.1701 - val_accuracy: 0.9277 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.7184 - accuracy: 0.9416 - val_loss: 0.3446 - val_accuracy: 0.9541 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.2260 - accuracy: 0.9628 - val_loss: 0.1435 - val_accuracy: 0.9691 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.1108 - accuracy: 0.9730 - val_loss: 0.0934 - val_accuracy: 0.9744 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0770 - accuracy: 0.9784 - val_loss: 0.0726 - val_accuracy: 0.9789 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0609 - accuracy: 0.9823 - val_loss: 0.0627 - val_accuracy: 0.9817 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0522 - accuracy: 0.9848 - val_loss: 0.0569 - val_accuracy: 0.9832 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0456 - accuracy: 0.9868 - val_loss: 0.0520 - val_accuracy: 0.9845 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0405 - accuracy: 0.9883 - val_loss: 0.0493 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0364 - accuracy: 0.9894 - val_loss: 0.0477 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 0.0437 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0296 - accuracy: 0.9915 - val_loss: 0.0423 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0269 - accuracy: 0.9924 - val_loss: 0.0420 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.0420 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.0423 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.0388 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0186 - accuracy: 0.9950 - val_loss: 0.0388 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.0400 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.0403 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.0371 - val_accuracy: 0.9901 - lr: 1.0000e-03\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0369 - val_accuracy: 0.9901 - lr: 1.0000e-03\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.0370 - val_accuracy: 0.9901 - lr: 1.0000e-03\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.0370 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.0370 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 0.0369 - val_accuracy: 0.9902 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 0.0369 - val_accuracy: 0.9902 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 0.0369 - val_accuracy: 0.9902 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.0369 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.0369 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.0369 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.0369 - val_accuracy: 0.9902 - lr: 1.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, double_dense_f1_scores, models[models_name[2]] = get_best_model(double_dense_models, double_dense_units)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfH3R8ifs2uH",
        "outputId": "2b16c6a0-4104-49b8-ee50-1d21fddf2575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 10ms/step\n",
            "41/41 [==============================] - 1s 10ms/step\n",
            "41/41 [==============================] - 1s 10ms/step\n",
            "41/41 [==============================] - 1s 11ms/step\n",
            "The best number of units is: 256.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY-asix9UOBH"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Train **all** models on the train set.\n",
        "* Evaluate **all** models on the validation set.\n",
        "* Compute metrics on the validation set.\n",
        "* Pick **at least** three seeds for robust estimation.\n",
        "* Pick the **best** performing model according to the observed validation set performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_val_score = {}\n",
        "best_val_pred = {}\n",
        "models_val_report = {}\n",
        "\n",
        "\n",
        "for model in models:\n",
        "  print(f\"{descriptions_dict[model]}\\n\")\n",
        "  models_val_score[model], best_val_pred[model], models_val_report[model] = compute_F1_score(models[model], validation_features_padded, validation_tags_padded, tag_to_index)\n",
        "  print(f\"The macro F1-score for model {model} is: {models_val_score[model]}.\\n\")\n",
        "\n",
        "\n",
        "best_models = sorted(models_val_score, key = models_val_score.get, reverse = True)[:2]"
      ],
      "metadata": {
        "id": "N3o5rFrDs6bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48328e76-2245-45c3-e0be-eb712e56ddc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline model (m_0): \n",
            " - Bi-directional LSTM layer. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "41/41 [==============================] - 0s 10ms/step\n",
            "The macro F1-score for model m_0 is: 0.7667518693664673.\n",
            "\n",
            "Additional bi-directional LSTM model (m_1): \n",
            " - Bi-directional LSTM layer. \n",
            " - Bi-directional LSTM layer. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "41/41 [==============================] - 1s 19ms/step\n",
            "The macro F1-score for model m_1 is: 0.7750726757833377.\n",
            "\n",
            "Additional dense layer model (m_2): \n",
            " - Bi-directional LSTM layer. \n",
            " - Time-distributed dense layer. \n",
            " - ReLU activation function. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "41/41 [==============================] - 0s 11ms/step\n",
            "The macro F1-score for model m_2 is: 0.7605632972975537.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_test_score = {}\n",
        "best_test_pred = {}\n",
        "models_test_report = {}\n",
        "\n",
        "for model in best_models:\n",
        "  print(f\"{descriptions_dict[model]}\\n\")\n",
        "  models_test_score[model], best_test_pred[model], models_test_report[model] = compute_F1_score(models[model], test_features_padded, test_tags_padded, tag_to_index)\n",
        "  print(f\"The macro F1-score, on the test set, for model {model} is: {models_test_score[model]}.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1miIqHQ7syNd",
        "outputId": "8c0f678e-20f3-4152-962c-4135c6ff18f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Additional bi-directional LSTM model (m_1): \n",
            " - Bi-directional LSTM layer. \n",
            " - Bi-directional LSTM layer. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "21/21 [==============================] - 0s 20ms/step\n",
            "The macro F1-score, on the test set, for model m_1 is: 0.7735930620632316.\n",
            "\n",
            "Baseline model (m_0): \n",
            " - Bi-directional LSTM layer. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "21/21 [==============================] - 0s 10ms/step\n",
            "The macro F1-score, on the test set, for model m_0 is: 0.7764972851995102.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2VxlJuYUOBH"
      },
      "source": [
        "# [Task 6 - 1.0 points] Error Analysis\n",
        "\n",
        "You are tasked to evaluate your best performing model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_masked_labels(true_labels, pred_labels, tag_to_index, punctuation_tag_list):\n",
        "\n",
        "  punctuation_indexes = [tag_to_index[tag] for tag in punctuation_tag_list]\n",
        "\n",
        "  mask = np.isin(true_labels, punctuation_indexes)\n",
        "  true = np.delete(true_labels, mask)\n",
        "  pred = np.delete(pred_labels, mask)\n",
        "\n",
        "  return true, pred, punctuation_indexes\n",
        "\n",
        "for model in best_models:\n",
        "\n",
        "  model_val_pred = np.argmax(best_val_pred[model], axis = 2).flatten()\n",
        "  true, pred, _ = get_masked_labels(validation_tags_padded.flatten(), model_val_pred, tag_to_index, punctuation_tag_list)\n",
        "  print(\"The error rate, on the validation set, for model {} is: {}%.\".format(model, np.sum(true != pred) * 100 / len(true)))\n",
        "\n",
        "  model_test_pred = np.argmax(best_test_pred[model], axis = 2).flatten()\n",
        "  true, pred, _ = get_masked_labels(test_tags_padded.flatten(), model_test_pred, tag_to_index, punctuation_tag_list)\n",
        "  print(\"The error rate, on the test set, for model {} is: {}%.\".format(model, np.sum(true != pred) * 100 / len(true)))\n"
      ],
      "metadata": {
        "id": "3lauwLfXs9vR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf74f2f-1252-4190-d19b-a6df4d2400d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The error rate, on the validation set, for model m_1 is: 10.410359292358198%.\n",
            "The error rate, on the test set, for model m_1 is: 9.54226381983036%.\n",
            "The error rate, on the validation set, for model m_0 is: 11.161772752142987%.\n",
            "The error rate, on the test set, for model m_0 is: 9.93711611582334%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model in best_models:\n",
        "\n",
        "  val_precision = 0\n",
        "  test_precision = 0\n",
        "  val_recall = 0\n",
        "  test_recall = 0\n",
        "\n",
        "  for tag in list(tag_to_index.keys()):\n",
        "\n",
        "    if tag not in punctuation_tag_list:\n",
        "      val_precision = val_precision + models_val_report[model][tag][\"precision\"]\n",
        "      test_precision = test_precision + models_test_report[model][tag][\"precision\"]\n",
        "      val_recall = val_recall + models_val_report[model][tag][\"recall\"]\n",
        "      test_recall = test_recall + models_test_report[model][tag][\"recall\"]\n",
        "\n",
        "  val_precision = val_precision / (len(list(tag_to_index.keys())) - len(punctuation_tag_list))\n",
        "  test_precision = test_precision / (len(list(tag_to_index.keys())) - len(punctuation_tag_list))\n",
        "  val_recall = val_recall / (len(list(tag_to_index.keys())) - len(punctuation_tag_list))\n",
        "  test_recall = test_recall / (len(list(tag_to_index.keys())) - len(punctuation_tag_list))\n",
        "\n",
        "  print(f\"The macro precision, on the validation set, for model {model} is: {val_precision}.\")\n",
        "  print(f\"The macro precision, on the test set, for model {model} is: {test_precision}.\")\n",
        "  print(f\"The macro recall, on the validation set, for model {model} is: {val_recall}.\")\n",
        "  print(f\"The macro recall, on the test set, for model {model} is: {test_recall}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5Vh9u4Rs2Yt",
        "outputId": "248a4635-372f-4a2f-bafa-d656c2b9305e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The macro precision, on the validation set, for model m_1 is: 0.7839906594391554.\n",
            "The macro precision, on the test set, for model m_1 is: 0.7755735456258689.\n",
            "The macro recall, on the validation set, for model m_1 is: 0.7779439873104167.\n",
            "The macro recall, on the test set, for model m_1 is: 0.7826815825372172.\n",
            "The macro precision, on the validation set, for model m_0 is: 0.7698285926465419.\n",
            "The macro precision, on the test set, for model m_0 is: 0.7810172057964292.\n",
            "The macro recall, on the validation set, for model m_0 is: 0.7756780444207914.\n",
            "The macro recall, on the test set, for model m_0 is: 0.7806723478763761.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOP_ERROR_RATES = 5\n",
        "\n",
        "for model in best_models:\n",
        "\n",
        "  print(f\"Model {model}:\\n\")\n",
        "\n",
        "  # Error rates.\n",
        "  error_rates = []\n",
        "  for i in range(len(test_tags)):\n",
        "    true, pred, punctuation_indexes = get_masked_labels(test_tags_padded[i], np.argmax(best_test_pred[model], axis = 2)[i], tag_to_index, punctuation_tag_list)\n",
        "    error_rates.append(np.sum(true != pred) * 100 / len(true))\n",
        "\n",
        "  most_mistakes = np.argpartition(error_rates, -TOP_ERROR_RATES)[-TOP_ERROR_RATES:]\n",
        "\n",
        "  for i in range(TOP_ERROR_RATES):\n",
        "    true, pred, _ = get_masked_labels(test_tags_padded[most_mistakes[i]], np.argmax(best_test_pred[model], axis = 2)[most_mistakes[i]], tag_to_index, punctuation_tag_list)\n",
        "    true = [tag for index in true for tag, value in tag_to_index.items() if value == index]\n",
        "    pred = [tag for index in pred for tag, value in tag_to_index.items() if value == index]\n",
        "    print(\"The true tags, without punctuation, are {}, while the predicted ones are {}.\\n\".format(true, pred))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87EQCKGJs6Qm",
        "outputId": "1edc47ba-1d3b-48bb-c005-a9396150b690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model m_1:\n",
            "\n",
            "The true tags, without punctuation, are ['NNP', 'VBZ', 'JJ', 'NNS', 'CC', 'VBZ', 'NN', 'NNS', 'CC', 'JJ', 'NN', 'NNS'], while the predicted ones are ['NN', 'NN', 'NN', 'NNS', 'CC', 'NN', 'NN', 'NNS', 'CC', 'NN', 'NN', 'NN'].\n",
            "\n",
            "The true tags, without punctuation, are ['NNP', 'VBZ', 'DT', 'JJ', 'JJ', 'NN', 'NN'], while the predicted ones are ['VBZ', 'VBZ', 'DT', 'NNP', 'NNP', 'NNP', 'NN'].\n",
            "\n",
            "The true tags, without punctuation, are ['NN', 'NNS', 'CC', 'NN'], while the predicted ones are ['NNP', 'NNPS', 'CC', 'NNP'].\n",
            "\n",
            "The true tags, without punctuation, are ['NNP'], while the predicted ones are ['NN'].\n",
            "\n",
            "The true tags, without punctuation, are ['NNPS', 'NNP', 'NNPS'], while the predicted ones are ['NNS', 'CC', 'NNP'].\n",
            "\n",
            "\n",
            "Model m_0:\n",
            "\n",
            "The true tags, without punctuation, are ['NNP', 'NNPS', 'NNP', 'NNS', 'VBD', 'RB', 'VBN', 'NN', 'CC', 'NN', 'VBD', 'IN', 'DT', 'NNS', 'NNS'], while the predicted ones are ['JJ', 'NNS', 'NNS', 'NNS', 'RB', 'IN', 'VBD', 'NN', 'CC', 'NN', 'VBD', 'IN', 'DT', 'NNS', 'NNS'].\n",
            "\n",
            "The true tags, without punctuation, are ['CC', 'DT', 'NNP', 'NNP', 'IN', 'NNPS', 'VBZ', 'DT', 'NN', 'NN', 'TO', 'VB', 'VBG', 'DT', 'NN'], while the predicted ones are ['CC', 'DT', 'NN', 'NN', 'IN', 'NNP', 'VBZ', 'DT', 'NNP', 'VBG', 'TO', 'VB', 'VB', 'DT', 'NN'].\n",
            "\n",
            "The true tags, without punctuation, are ['NN', 'NNS', 'CC', 'NN'], while the predicted ones are ['NNP', 'NNS', 'CC', 'VB'].\n",
            "\n",
            "The true tags, without punctuation, are ['NNP'], while the predicted ones are ['NN'].\n",
            "\n",
            "The true tags, without punctuation, are ['NNPS', 'NNP', 'NNPS'], while the predicted ones are ['NNS', 'CC', 'NNP'].\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McywV-yuUOBG"
      },
      "source": [
        "### More about OOV\n",
        "\n",
        "For a given token:\n",
        "\n",
        "* **If in train set**: add to vocabulary and assign an embedding (use GloVe if token in GloVe, custom embedding otherwise).\n",
        "* **If in val/test set**: assign special token if not in vocabulary and assign custom embedding.\n",
        "\n",
        "Your vocabulary **should**:\n",
        "\n",
        "* Contain all tokens in train set; or\n",
        "* Union of tokens in train set and in GloVe $\\rightarrow$ we make use of existing knowledge!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S18NPKpbUOBG"
      },
      "source": [
        "**Note**: What about OOV tokens?\n",
        "   * All the tokens in the **training** set that are not in GloVe **must** be added to the vocabulary.\n",
        "   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **special token** (e.g., [UNK]) and a **static** embedding.\n",
        "   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, etc...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9rBPyUHUOBG"
      },
      "source": [
        "### Token to embedding mapping\n",
        "\n",
        "You can follow two approaches for encoding tokens in your POS tagger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBYfc2hvUOBG"
      },
      "source": [
        "### Work directly with embeddings\n",
        "\n",
        "- Compute the embedding of each input token\n",
        "- Feed the mini-batches of shape (batch_size, # tokens, embedding_dim) to your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcjPz6k6UOBG"
      },
      "source": [
        "### Work with Embedding layer\n",
        "\n",
        "- Encode input tokens to token ids\n",
        "- Define a Embedding layer as the first layer of your model\n",
        "- Compute the embedding matrix of all known tokens (i.e., tokens in your vocabulary)\n",
        "- Initialize the Embedding layer with the computed embedding matrix\n",
        "- You are **free** to set the Embedding layer trainable or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIzeVFVtUOBG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35pWrjaYUOBH"
      },
      "source": [
        "### Padding\n",
        "\n",
        "Pay attention to padding tokens!\n",
        "\n",
        "Your model **should not** be penalized on those tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VidA9N-NUOBH"
      },
      "source": [
        "#### How to?\n",
        "\n",
        "There are two main ways.\n",
        "\n",
        "However, their implementation depends on the neural library you are using.\n",
        "\n",
        "- Embedding layer\n",
        "- Custom loss to compute average cross-entropy on non-padding tokens only\n",
        "\n",
        "**Note**: This is a **recommendation**, but we **do not penalize** for missing workarounds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agcN7EP3UOBH"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Compare the errors made on the validation and test sets.\n",
        "* Aggregate model errors into categories (if possible)\n",
        "* Comment the about errors and propose possible solutions on how to address them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6Ej8DaaUOBI"
      },
      "source": [
        "# [Task 7 - 1.0 points] Report\n",
        "\n",
        "Wrap up your experiment in a short report (up to 2 pages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quST47qOUOBI"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Use the NLP course report template.\n",
        "* Summarize each task in the report following the provided template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZSyFoJVUOBI"
      },
      "source": [
        "### Recommendations\n",
        "\n",
        "The report is not a copy-paste of graphs, tables, and command outputs.\n",
        "\n",
        "* Summarize classification performance in Table format.\n",
        "* **Do not** report command outputs or screenshots.\n",
        "* Report learning curves in Figure format.\n",
        "* The error analysis section should summarize your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix_xxFBBUOBI"
      },
      "source": [
        "# Submission\n",
        "\n",
        "* **Submit** your report in PDF format.\n",
        "* **Submit** your python notebook.\n",
        "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc...\n",
        "* You can upload **model weights** in a cloud repository and report the link in the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT453TKgUOBI"
      },
      "source": [
        "# FAQ\n",
        "\n",
        "Please check this frequently asked questions before contacting us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e5qwPTpUOBI"
      },
      "source": [
        "### Execution Order\n",
        "\n",
        "You are **free** to address tasks in any order (if multiple orderings are available)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoDk05_tUOBI"
      },
      "source": [
        "### Trainable Embeddings\n",
        "\n",
        "You are **free** to define a trainable or non-trainable Embedding layer to load the GloVe embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIwLVPngUOBI"
      },
      "source": [
        "### Model architecture\n",
        "\n",
        "You **should not** change the architecture of a model (i.e., its layers).\n",
        "\n",
        "However, you are **free** to play with their hyper-parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-P0mGUHUOBI"
      },
      "source": [
        "### Neural Libraries\n",
        "\n",
        "You are **free** to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIEICpsVUOBI"
      },
      "source": [
        "### Keras TimeDistributed Dense layer\n",
        "\n",
        "If you are using Keras, we recommend wrapping the final Dense layer with `TimeDistributed`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA_2bbsqUOBI"
      },
      "source": [
        "### Robust Evaluation\n",
        "\n",
        "Each model is trained with at least 3 random seeds.\n",
        "\n",
        "Task 4 requires you to compute the average performance over the 3 seeds and its corresponding standard deviation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFLFO0HlUOBJ"
      },
      "source": [
        "### Model Selection for Analysis\n",
        "\n",
        "To carry out the error analysis you are **free** to either\n",
        "\n",
        "* Pick examples or perform comparisons with an individual seed run model (e.g., Baseline seed 1337)\n",
        "* Perform ensembling via, for instance, majority voting to obtain a single model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vkxw9SuUOBJ"
      },
      "source": [
        "### Error Analysis\n",
        "\n",
        "Some topics for discussion include:\n",
        "   * Model performance on most/less frequent classes.\n",
        "   * Precision/Recall curves.\n",
        "   * Confusion matrices.\n",
        "   * Specific misclassified samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxAQqY0DUOBJ"
      },
      "source": [
        "### Punctuation\n",
        "\n",
        "**Do not** remove punctuation from documents since it may be helpful to the model.\n",
        "\n",
        "You should **ignore** it during metrics computation.\n",
        "\n",
        "If you are curious, you can run additional experiments to verify the impact of removing punctuation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boXLXjbKUOBJ"
      },
      "source": [
        "# The End"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}